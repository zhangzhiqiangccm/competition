{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"tensorflow-1.13.1","display_name":"TensorFlow-1.13.1","language":"python"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"2020语言与智能技术竞赛.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_IlY1GnV83T3","colab_type":"text"},"source":["# 2020语言与智能技术竞赛：机器阅读理解任务\n","https://aistudio.baidu.com/aistudio/competition/detail/28\n","\n","机器阅读理解 (MRC, Machine Reading Comprehension) 是指让机器阅读文本，然后回答和阅读内容相关的问题。阅读理解是自然语言处理和人工智能领域的重要前沿课题，对于提升机器的智能水平、使机器具有持续知识获取的能力等具有重要价值，近年来受到学术界和工业界的广泛关注。\n","\n","中国中文信息学会(CCF, the China Computer Federation)、中国计算机学会(CIPS, Chinese Information Processing Society of China)和百度公司已经于2018和2019年连续联合举办了机器阅读理解评测，极大地推动了中文机器阅读理解技术的发展。随着技术的进步，当前的一些模型已经能够在一些阅读理解测试集上取得较好的性能。但在实际应用中，这些模型所表现出的鲁棒性仍然较差。因此，“2020 语言与智能技术竞赛”将继续举办机器阅读理解任务的评测，重点关注阅读理解模型在真实应用场景中的鲁棒性，挑战模型的过敏感性、过稳定性以及泛化能力等。\n","\n","本次评测将提供面向真实应用场景的高质量中文阅读理解数据集DuReader Robust，旨在为研究者和开发者提供学术和技术交流的平台， 进一步提升机器阅读理解的研究水平，推动语言理解和人工智能领域技术和应用的发展。本次竞赛将在第五届“语言与智能高峰论坛”举办技术交流论坛和颁奖仪式。 诚邀学术界和工业界的研究者和开发者参加本次竞赛！\n","\n","## 赛程安排\n","    2020/3/10 \t启动竞赛报名，发放样例数据\n","    2020/3/31 \t开放评测入口和排行榜，对报名者发放全部训练数据和第一批测试数据\n","    2020/5/12 \t报名截止\n","    2020/5/13 \t发放最终测试数据\n","    2020/5/20 \t系统结果提交截止\n","    2020/5/30 \t公布竞赛结果，接收系统报告和论文\n","    2020/6/30 \t论文提交截止日期\n","    2020/7 \t在“语言与智能高峰论坛”上交流和颁奖\n","\n","## 数据介绍 Data\n","\n","本次竞赛数据集共包含约21K问题，其中包括15K训练集，约1.4K领域内开发集和5K测试集。测试集包含了领域内测试集和鲁棒性测试集，其中鲁棒性测试集包括了过敏感测试集、过稳定测试集以及泛化能力测试集。全部数据集将分为4个部分供参赛用户下载：\n","\n","1.训练集：共15K样本，用于竞赛模型训练。\n","2.开发集：共1.4K样本，包含答案，用于竞赛模型训练和参数调试。\n","3.测试集1：共2K个样本，主要包含了大部分领域内测试集和少部分鲁棒性测试集，不提供参考答案，用于参赛者在比赛平台上自助验证模型效果。为了防止针对测试集的调试，数据中将会额外加入混淆数据。\n","4.测试集2：是本次竞赛最终测试数据（含测试集1），共5K问题，包含全部领域内测试集和鲁棒性测试集，不提供参考答案。为了防止针对测试集的调试，数据中将会额外加入混淆数据。该部分数据结果不能在比赛平台上自助验证。\n","### 数据样本 Data Sample\n","\n","平台提供的数据为JSON文件格式，样例如下:\n","\n","    {\n","        \"data\": [\n","            {\n","                \"paragraphs\": [\n","                    {\n","                        \"qas\": [\n","                            {\n","                                \"question\": \"非洲气候带\", \n","                                \"id\": \"bd664cb57a602ae784ae24364a602674\", \n","                                \"answers\": [\n","                                    {\n","                                        \"text\": \"热带气候\", \n","                                        \"answer_start\": 45\n","                                    }\n","                                ]\n","                            }\n","                        ], \n","                        \"context\": \"1、全年气温高，有热带大陆之称。主要原因在与赤道穿过大陆中部，位于南北纬30度之间，主要是热带气候，没有温带和寒带… \n","                    }, \n","                    {\n","                        \"qas\": [\n","                            {\n","                                \"question\": \"韩国全称\", \n","                                \"id\": \"a7eec8cf0c55077e667e0d85b45a6b34\", \n","                                \"answers\": [\n","                                    {\n","                                        \"text\": \"大韩民国\", \n","                                        \"answer_start\": 5\n","                                    }\n","                                ]\n","                            }\n","                        ], \n","                        \"context\": \"韩国全称“大韩民国”，位于朝鲜半岛南部，隔“三八线”与朝鲜民主主义人民共和国相邻，面积9.93万平方公理… \"\n","                    }\n","                ], \n","                \"title\": \"\"\n","            }\n","        ]\n","    }\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ENz-l7O683T4","colab_type":"text"},"source":["* 百度LIC2020的机器阅读理解赛道，非官方baseline\n","* 直接用RoBERTa+Softmax预测首尾\n","* BASE模型在第一期测试集上能达到0.69的F1，优于官方baseline\n","* 如果你显存足够，可以换用RoBERTa Large模型，F1可以到0.71"]},{"cell_type":"code","metadata":{"trusted":true,"id":"b4aRVkx883T4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":487},"executionInfo":{"status":"ok","timestamp":1595855360006,"user_tz":-480,"elapsed":14211,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}},"outputId":"9a091e7c-0c11-4c75-80ed-003169b1d478"},"source":["!pip install --upgrade pip\n","!pip install bert4keras"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pip\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/84/23ed6a1796480a6f1a2d38f2802901d078266bda38388954d01d3f2e821d/pip-20.1.1-py2.py3-none-any.whl (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 2.7MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Found existing installation: pip 19.3.1\n","    Uninstalling pip-19.3.1:\n","      Successfully uninstalled pip-19.3.1\n","Successfully installed pip-20.1.1\n","Collecting bert4keras\n","  Downloading bert4keras-0.8.4.tar.gz (39 kB)\n","Requirement already satisfied: keras<=2.3.1 in /usr/local/lib/python3.6/dist-packages (from bert4keras) (2.3.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.1.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.15.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.0.8)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (2.10.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.18.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras<=2.3.1->bert4keras) (1.4.1)\n","Building wheels for collected packages: bert4keras\n","  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert4keras: filename=bert4keras-0.8.4-py3-none-any.whl size=37855 sha256=d86611a7e7540d2dde0e4ea44d9e2e8d5fc2573bcddb4125f31f7360462f46e5\n","  Stored in directory: /root/.cache/pip/wheels/71/d1/a7/d54027d32e1f308c36aa561e08e6d05323a71b8ddc0d6a5f23\n","Successfully built bert4keras\n","Installing collected packages: bert4keras\n","Successfully installed bert4keras-0.8.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9cr6v0WTVdcH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"status":"ok","timestamp":1595855366926,"user_tz":-480,"elapsed":3113,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}},"outputId":"03241e83-831d-4329-a219-b3276897f8bb"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mon Jul 27 13:09:25 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"T_6c_DPF83T9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595855398904,"user_tz":-480,"elapsed":2697,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}},"outputId":"8544d19b-2807-4a7a-a187-d18f00961d67"},"source":["import json, os\n","import numpy as np\n","from bert4keras.backend import keras, K\n","from bert4keras.models import build_transformer_model\n","from bert4keras.tokenizers import Tokenizer\n","from bert4keras.optimizers import Adam\n","from bert4keras.snippets import sequence_padding, DataGenerator\n","from bert4keras.snippets import open\n","from keras.layers import Layer, Dense, Permute\n","from keras.models import Model\n","from tqdm import tqdm\n","\n","# 基本信息\n","maxlen = 128\n","epochs = 20\n","batch_size = 4\n","learing_rate = 2e-5"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"63X9pOVw83T_","colab_type":"text"},"source":["# 下载模型"]},{"cell_type":"code","metadata":{"id":"W6NMYxpM9TPO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1595855442080,"user_tz":-480,"elapsed":25443,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}},"outputId":"9364ae70-2dfe-4093-e27c-327e3c495f4a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OfZrLiTm-hz7","colab_type":"text"},"source":["## 解压"]},{"cell_type":"code","metadata":{"id":"uaUwhtw19frG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1595855464112,"user_tz":-480,"elapsed":4479,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}},"outputId":"f4c1caf3-a6c7-408c-f2bc-92064c132360"},"source":[" !ls /content/drive/\"My Drive\"/kaikeba/project03/roberta/data"],"execution_count":5,"outputs":[{"output_type":"stream","text":["bert_config.json\t\t\t\t    dev.json.pred.json\n","bert_model.ckpt.data-00000-of-00001\t\t    evaluate.py\n","bert_model.ckpt.index\t\t\t\t    License.docx\n","bert_model.ckpt.meta\t\t\t\t    __pycache__\n","chinese_roberta_wwm_large_ext_L-24_H-1024_A-16.zip  README.md\n","demo\t\t\t\t\t\t    test1.json\n","demo_dev.json\t\t\t\t\t    test2.json\n","demo_dev.json.pred.json\t\t\t\t    train.json\n","demo_train.json\t\t\t\t\t    vocab.txt\n","dev.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0NURyS-f-S8O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1595855527636,"user_tz":-480,"elapsed":36454,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}},"outputId":"1f592b7b-51c4-40a3-f563-ba1a906a8a00"},"source":["! unzip -o /content/drive/\"My Drive\"/kaikeba/project03/roberta/data/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16.zip -d /content/drive/\"My Drive\"/kaikeba/project03/roberta/data"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Archive:  /content/drive/My Drive/kaikeba/project03/roberta/data/chinese_roberta_wwm_large_ext_L-24_H-1024_A-16.zip\n","  inflating: /content/drive/My Drive/kaikeba/project03/roberta/data/bert_config.json  \n","  inflating: /content/drive/My Drive/kaikeba/project03/roberta/data/bert_model.ckpt.data-00000-of-00001  \n","  inflating: /content/drive/My Drive/kaikeba/project03/roberta/data/bert_model.ckpt.index  \n","  inflating: /content/drive/My Drive/kaikeba/project03/roberta/data/bert_model.ckpt.meta  \n","  inflating: /content/drive/My Drive/kaikeba/project03/roberta/data/vocab.txt  \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4EIYmRCaA_nH","colab_type":"text"},"source":["## 设置数据路径"]},{"cell_type":"code","metadata":{"trusted":true,"id":"ItUURTQ183UA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855539058,"user_tz":-480,"elapsed":1099,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["data_dir='/content/drive/My Drive/kaikeba/project03/roberta/data'\n","output_dir='/content/drive/My Drive/kaikeba/project03/roberta/output'"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pKJKHQkz83UP","colab_type":"text"},"source":["# 模型路径"]},{"cell_type":"markdown","metadata":{"id":"wmRzI7QT83UP","colab_type":"text"},"source":["## bert"]},{"cell_type":"code","metadata":{"trusted":true,"id":"NcK7H86G83UT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855556733,"user_tz":-480,"elapsed":961,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["bert_dir = '/content/drive/My Drive/kaikeba/project03/roberta/data'\n","config_path = f'{bert_dir}/bert_config.json'\n","checkpoint_path = f'{bert_dir}/bert_model.ckpt'\n","dict_path = f'{bert_dir}/vocab.txt'"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DWUGIH8T83UV","colab_type":"text"},"source":["# 加载数据"]},{"cell_type":"code","metadata":{"trusted":true,"id":"vjf9nl7I83UW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855602931,"user_tz":-480,"elapsed":983,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["def load_data(filename):\n","    D = []\n","    for d in json.load(open(filename))['data'][0]['paragraphs']:\n","        for qa in d['qas']:\n","            D.append([\n","                qa['id'], d['context'], qa['question'],\n","                [a['text'] for a in qa.get('answers', [])]\n","            ])\n","    return D"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IorbHPdP83UY","colab_type":"text"},"source":["# 读取数据"]},{"cell_type":"code","metadata":{"trusted":true,"id":"w70wRIw883UY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855610658,"user_tz":-480,"elapsed":1699,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["train_data = load_data(\n","    # os.path.join(data_dir,'train.json')\n","    os.path.join(data_dir,'demo_train.json')\n",")"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"lKbIzbKxaCic","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"status":"ok","timestamp":1595855621261,"user_tz":-480,"elapsed":1086,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}},"outputId":"adb0d275-3b3f-407e-fa94-737f3ae8bae6"},"source":["train_data[0]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['bd664cb57a602ae784ae24364a602674',\n"," '1、全年气温高，有热带大陆之称。主要原因在与赤道穿过大陆中部，位于南北纬30度之间，主要是热带气候，没有温带和寒带。2、气候带呈明显带状分布，且南北对称。原因在于赤道穿过大陆中部，整个大陆基本被赤道均分为两部分。因此，纬度地带性明显。气候带以热带雨林为中心，向南北依次分布着热带草原、热带沙漠和地中海式气候。3、气候炎热干燥。第一：热带雨林气候面积较小，主要位于刚果河流域，面积较小。第二，地中海式气候，位于大陆的南北边缘，面积较小。夏季炎热而干旱，冬季温暖而湿润。第三，面积较大热带草原气候，有明显的干湿季。第四，热带沙漠气候主要位于撒哈拉大沙漠和西南角狭长地带。而撒哈拉沙漠占非洲总面积的1/4，全年炎热干燥，日照时间长，昼夜温差大。总之，全非洲纬度低，气温高；干燥地区广，常年湿润地区面积小。',\n"," '非洲气候带',\n"," ['热带气候']]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"k2SDWmUv83Ua","colab_type":"text"},"source":["# 建立分词器"]},{"cell_type":"code","metadata":{"trusted":true,"id":"8G1BqYjh83Ub","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855631388,"user_tz":-480,"elapsed":1157,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["tokenizer = Tokenizer(dict_path, do_lower_case=True)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K399Sc5E83Ud","colab_type":"text"},"source":["# 子串搜索"]},{"cell_type":"code","metadata":{"trusted":true,"id":"C2Y8mXlE83Ue","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855636749,"user_tz":-480,"elapsed":957,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["def search(pattern, sequence):\n","    \"\"\"从sequence中寻找子串pattern\n","    如果找到，返回第一个下标；否则返回-1。\n","    \"\"\"\n","    n = len(pattern)\n","    for i in range(len(sequence)):\n","        if sequence[i:i + n] == pattern:\n","            return i\n","    return -1"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QHMtsGYC83Uh","colab_type":"text"},"source":["# 数据生成器"]},{"cell_type":"code","metadata":{"trusted":true,"id":"fypxJpY583Uh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855716262,"user_tz":-480,"elapsed":1120,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["class data_generator(DataGenerator):\n","    def __iter__(self, random=False):\n","        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n","        for is_end, item in self.sample(random):\n","            context, question, answers = item[1:]\n","            token_ids, segment_ids = tokenizer.encode(\n","                question, context, maxlen=maxlen\n","            )\n","            a = np.random.choice(answers)\n","            a_token_ids = tokenizer.encode(a)[0][1:-1]\n","            start_index = search(a_token_ids, token_ids)\n","            if start_index != -1:\n","                labels = [[start_index], [start_index + len(a_token_ids) - 1]]\n","                batch_token_ids.append(token_ids)\n","                batch_segment_ids.append(segment_ids)\n","                batch_labels.append(labels)\n","                if len(batch_token_ids) == self.batch_size or is_end:\n","                    batch_token_ids = sequence_padding(batch_token_ids)\n","                    batch_segment_ids = sequence_padding(batch_segment_ids)\n","                    batch_labels = sequence_padding(batch_labels)\n","                    yield [batch_token_ids, batch_segment_ids], batch_labels\n","                    batch_token_ids, batch_segment_ids, batch_labels = [], [], []"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fvx3sVXK83Uj","colab_type":"text"},"source":["# Mask"]},{"cell_type":"code","metadata":{"trusted":true,"id":"jbuoJCYJ83Uk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855723296,"user_tz":-480,"elapsed":1091,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["class MaskedSoftmax(Layer):\n","    \"\"\"\n","    在序列长度那一维进行softmax，并mask掉padding部分\n","    \"\"\"\n","    def compute_mask(self, inputs, mask=None):\n","        return None\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            mask = K.cast(mask, K.floatx())\n","            mask = K.expand_dims(mask, 2)\n","            inputs = inputs - (1.0 - mask) * 1e12\n","        return K.softmax(inputs, 1)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n2vYtLW683Um","colab_type":"text"},"source":["# 构建模型"]},{"cell_type":"code","metadata":{"trusted":true,"id":"kNmeanl_83Um","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595855749908,"user_tz":-480,"elapsed":18452,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}},"outputId":"3164862d-444c-48e6-f31a-2f79a1c9c94c"},"source":["model = build_transformer_model(\n","    config_path,\n","    checkpoint_path,\n",")\n","\n","output = Dense(2)(model.output)\n","output = MaskedSoftmax()(output)\n","output = Permute((2, 1))(output)\n","\n","model = Model(model.input, output)\n","model.summary()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Input-Token (InputLayer)        (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Input-Segment (InputLayer)      (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Embedding-Token (Embedding)     (None, None, 1024)   21635072    Input-Token[0][0]                \n","__________________________________________________________________________________________________\n","Embedding-Segment (Embedding)   (None, None, 1024)   2048        Input-Segment[0][0]              \n","__________________________________________________________________________________________________\n","Embedding-Token-Segment (Add)   (None, None, 1024)   0           Embedding-Token[0][0]            \n","                                                                 Embedding-Segment[0][0]          \n","__________________________________________________________________________________________________\n","Embedding-Position (PositionEmb (None, None, 1024)   524288      Embedding-Token-Segment[0][0]    \n","__________________________________________________________________________________________________\n","Embedding-Norm (LayerNormalizat (None, None, 1024)   2048        Embedding-Position[0][0]         \n","__________________________________________________________________________________________________\n","Embedding-Dropout (Dropout)     (None, None, 1024)   0           Embedding-Norm[0][0]             \n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 1024)   4198400     Embedding-Dropout[0][0]          \n","                                                                 Embedding-Dropout[0][0]          \n","                                                                 Embedding-Dropout[0][0]          \n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 1024)   0           Embedding-Dropout[0][0]          \n","                                                                 Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward (Feed (None, None, 1024)   8393728     Transformer-0-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward-Dropo (None, None, 1024)   0           Transformer-0-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward-Add ( (None, None, 1024)   0           Transformer-0-MultiHeadSelfAttent\n","                                                                 Transformer-0-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-0-FeedForward-Norm  (None, None, 1024)   2048        Transformer-0-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-0-FeedForward-Norm[0]\n","                                                                 Transformer-0-FeedForward-Norm[0]\n","                                                                 Transformer-0-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-0-FeedForward-Norm[0]\n","                                                                 Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward (Feed (None, None, 1024)   8393728     Transformer-1-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward-Dropo (None, None, 1024)   0           Transformer-1-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward-Add ( (None, None, 1024)   0           Transformer-1-MultiHeadSelfAttent\n","                                                                 Transformer-1-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-1-FeedForward-Norm  (None, None, 1024)   2048        Transformer-1-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-1-FeedForward-Norm[0]\n","                                                                 Transformer-1-FeedForward-Norm[0]\n","                                                                 Transformer-1-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-1-FeedForward-Norm[0]\n","                                                                 Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward (Feed (None, None, 1024)   8393728     Transformer-2-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward-Dropo (None, None, 1024)   0           Transformer-2-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward-Add ( (None, None, 1024)   0           Transformer-2-MultiHeadSelfAttent\n","                                                                 Transformer-2-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-2-FeedForward-Norm  (None, None, 1024)   2048        Transformer-2-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-2-FeedForward-Norm[0]\n","                                                                 Transformer-2-FeedForward-Norm[0]\n","                                                                 Transformer-2-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-2-FeedForward-Norm[0]\n","                                                                 Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward (Feed (None, None, 1024)   8393728     Transformer-3-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward-Dropo (None, None, 1024)   0           Transformer-3-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward-Add ( (None, None, 1024)   0           Transformer-3-MultiHeadSelfAttent\n","                                                                 Transformer-3-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-3-FeedForward-Norm  (None, None, 1024)   2048        Transformer-3-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-3-FeedForward-Norm[0]\n","                                                                 Transformer-3-FeedForward-Norm[0]\n","                                                                 Transformer-3-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-3-FeedForward-Norm[0]\n","                                                                 Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward (Feed (None, None, 1024)   8393728     Transformer-4-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward-Dropo (None, None, 1024)   0           Transformer-4-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward-Add ( (None, None, 1024)   0           Transformer-4-MultiHeadSelfAttent\n","                                                                 Transformer-4-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-4-FeedForward-Norm  (None, None, 1024)   2048        Transformer-4-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-4-FeedForward-Norm[0]\n","                                                                 Transformer-4-FeedForward-Norm[0]\n","                                                                 Transformer-4-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-4-FeedForward-Norm[0]\n","                                                                 Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward (Feed (None, None, 1024)   8393728     Transformer-5-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward-Dropo (None, None, 1024)   0           Transformer-5-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward-Add ( (None, None, 1024)   0           Transformer-5-MultiHeadSelfAttent\n","                                                                 Transformer-5-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-5-FeedForward-Norm  (None, None, 1024)   2048        Transformer-5-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-5-FeedForward-Norm[0]\n","                                                                 Transformer-5-FeedForward-Norm[0]\n","                                                                 Transformer-5-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-5-FeedForward-Norm[0]\n","                                                                 Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward (Feed (None, None, 1024)   8393728     Transformer-6-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward-Dropo (None, None, 1024)   0           Transformer-6-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward-Add ( (None, None, 1024)   0           Transformer-6-MultiHeadSelfAttent\n","                                                                 Transformer-6-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-6-FeedForward-Norm  (None, None, 1024)   2048        Transformer-6-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-6-FeedForward-Norm[0]\n","                                                                 Transformer-6-FeedForward-Norm[0]\n","                                                                 Transformer-6-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-6-FeedForward-Norm[0]\n","                                                                 Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward (Feed (None, None, 1024)   8393728     Transformer-7-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward-Dropo (None, None, 1024)   0           Transformer-7-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward-Add ( (None, None, 1024)   0           Transformer-7-MultiHeadSelfAttent\n","                                                                 Transformer-7-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-7-FeedForward-Norm  (None, None, 1024)   2048        Transformer-7-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-7-FeedForward-Norm[0]\n","                                                                 Transformer-7-FeedForward-Norm[0]\n","                                                                 Transformer-7-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-7-FeedForward-Norm[0]\n","                                                                 Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward (Feed (None, None, 1024)   8393728     Transformer-8-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward-Dropo (None, None, 1024)   0           Transformer-8-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward-Add ( (None, None, 1024)   0           Transformer-8-MultiHeadSelfAttent\n","                                                                 Transformer-8-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-8-FeedForward-Norm  (None, None, 1024)   2048        Transformer-8-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-8-FeedForward-Norm[0]\n","                                                                 Transformer-8-FeedForward-Norm[0]\n","                                                                 Transformer-8-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-8-FeedForward-Norm[0]\n","                                                                 Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward (Feed (None, None, 1024)   8393728     Transformer-9-MultiHeadSelfAttent\n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward-Dropo (None, None, 1024)   0           Transformer-9-FeedForward[0][0]  \n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward-Add ( (None, None, 1024)   0           Transformer-9-MultiHeadSelfAttent\n","                                                                 Transformer-9-FeedForward-Dropout\n","__________________________________________________________________________________________________\n","Transformer-9-FeedForward-Norm  (None, None, 1024)   2048        Transformer-9-FeedForward-Add[0][\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-9-FeedForward-Norm[0]\n","                                                                 Transformer-9-FeedForward-Norm[0]\n","                                                                 Transformer-9-FeedForward-Norm[0]\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-9-FeedForward-Norm[0]\n","                                                                 Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward (Fee (None, None, 1024)   8393728     Transformer-10-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward-Drop (None, None, 1024)   0           Transformer-10-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward-Add  (None, None, 1024)   0           Transformer-10-MultiHeadSelfAtten\n","                                                                 Transformer-10-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-10-FeedForward-Norm (None, None, 1024)   2048        Transformer-10-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-10-FeedForward-Norm[0\n","                                                                 Transformer-10-FeedForward-Norm[0\n","                                                                 Transformer-10-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-10-FeedForward-Norm[0\n","                                                                 Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward (Fee (None, None, 1024)   8393728     Transformer-11-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward-Drop (None, None, 1024)   0           Transformer-11-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward-Add  (None, None, 1024)   0           Transformer-11-MultiHeadSelfAtten\n","                                                                 Transformer-11-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-11-FeedForward-Norm (None, None, 1024)   2048        Transformer-11-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-12-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-11-FeedForward-Norm[0\n","                                                                 Transformer-11-FeedForward-Norm[0\n","                                                                 Transformer-11-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-12-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-12-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-12-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-11-FeedForward-Norm[0\n","                                                                 Transformer-12-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-12-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-12-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-12-FeedForward (Fee (None, None, 1024)   8393728     Transformer-12-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-12-FeedForward-Drop (None, None, 1024)   0           Transformer-12-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-12-FeedForward-Add  (None, None, 1024)   0           Transformer-12-MultiHeadSelfAtten\n","                                                                 Transformer-12-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-12-FeedForward-Norm (None, None, 1024)   2048        Transformer-12-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-13-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-12-FeedForward-Norm[0\n","                                                                 Transformer-12-FeedForward-Norm[0\n","                                                                 Transformer-12-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-13-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-13-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-13-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-12-FeedForward-Norm[0\n","                                                                 Transformer-13-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-13-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-13-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-13-FeedForward (Fee (None, None, 1024)   8393728     Transformer-13-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-13-FeedForward-Drop (None, None, 1024)   0           Transformer-13-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-13-FeedForward-Add  (None, None, 1024)   0           Transformer-13-MultiHeadSelfAtten\n","                                                                 Transformer-13-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-13-FeedForward-Norm (None, None, 1024)   2048        Transformer-13-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-14-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-13-FeedForward-Norm[0\n","                                                                 Transformer-13-FeedForward-Norm[0\n","                                                                 Transformer-13-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-14-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-14-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-14-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-13-FeedForward-Norm[0\n","                                                                 Transformer-14-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-14-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-14-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-14-FeedForward (Fee (None, None, 1024)   8393728     Transformer-14-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-14-FeedForward-Drop (None, None, 1024)   0           Transformer-14-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-14-FeedForward-Add  (None, None, 1024)   0           Transformer-14-MultiHeadSelfAtten\n","                                                                 Transformer-14-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-14-FeedForward-Norm (None, None, 1024)   2048        Transformer-14-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-15-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-14-FeedForward-Norm[0\n","                                                                 Transformer-14-FeedForward-Norm[0\n","                                                                 Transformer-14-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-15-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-15-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-15-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-14-FeedForward-Norm[0\n","                                                                 Transformer-15-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-15-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-15-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-15-FeedForward (Fee (None, None, 1024)   8393728     Transformer-15-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-15-FeedForward-Drop (None, None, 1024)   0           Transformer-15-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-15-FeedForward-Add  (None, None, 1024)   0           Transformer-15-MultiHeadSelfAtten\n","                                                                 Transformer-15-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-15-FeedForward-Norm (None, None, 1024)   2048        Transformer-15-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-16-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-15-FeedForward-Norm[0\n","                                                                 Transformer-15-FeedForward-Norm[0\n","                                                                 Transformer-15-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-16-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-16-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-16-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-15-FeedForward-Norm[0\n","                                                                 Transformer-16-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-16-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-16-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-16-FeedForward (Fee (None, None, 1024)   8393728     Transformer-16-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-16-FeedForward-Drop (None, None, 1024)   0           Transformer-16-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-16-FeedForward-Add  (None, None, 1024)   0           Transformer-16-MultiHeadSelfAtten\n","                                                                 Transformer-16-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-16-FeedForward-Norm (None, None, 1024)   2048        Transformer-16-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-17-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-16-FeedForward-Norm[0\n","                                                                 Transformer-16-FeedForward-Norm[0\n","                                                                 Transformer-16-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-17-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-17-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-17-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-16-FeedForward-Norm[0\n","                                                                 Transformer-17-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-17-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-17-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-17-FeedForward (Fee (None, None, 1024)   8393728     Transformer-17-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-17-FeedForward-Drop (None, None, 1024)   0           Transformer-17-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-17-FeedForward-Add  (None, None, 1024)   0           Transformer-17-MultiHeadSelfAtten\n","                                                                 Transformer-17-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-17-FeedForward-Norm (None, None, 1024)   2048        Transformer-17-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-18-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-17-FeedForward-Norm[0\n","                                                                 Transformer-17-FeedForward-Norm[0\n","                                                                 Transformer-17-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-18-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-18-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-18-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-17-FeedForward-Norm[0\n","                                                                 Transformer-18-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-18-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-18-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-18-FeedForward (Fee (None, None, 1024)   8393728     Transformer-18-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-18-FeedForward-Drop (None, None, 1024)   0           Transformer-18-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-18-FeedForward-Add  (None, None, 1024)   0           Transformer-18-MultiHeadSelfAtten\n","                                                                 Transformer-18-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-18-FeedForward-Norm (None, None, 1024)   2048        Transformer-18-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-19-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-18-FeedForward-Norm[0\n","                                                                 Transformer-18-FeedForward-Norm[0\n","                                                                 Transformer-18-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-19-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-19-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-19-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-18-FeedForward-Norm[0\n","                                                                 Transformer-19-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-19-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-19-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-19-FeedForward (Fee (None, None, 1024)   8393728     Transformer-19-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-19-FeedForward-Drop (None, None, 1024)   0           Transformer-19-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-19-FeedForward-Add  (None, None, 1024)   0           Transformer-19-MultiHeadSelfAtten\n","                                                                 Transformer-19-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-19-FeedForward-Norm (None, None, 1024)   2048        Transformer-19-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-20-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-19-FeedForward-Norm[0\n","                                                                 Transformer-19-FeedForward-Norm[0\n","                                                                 Transformer-19-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-20-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-20-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-20-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-19-FeedForward-Norm[0\n","                                                                 Transformer-20-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-20-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-20-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-20-FeedForward (Fee (None, None, 1024)   8393728     Transformer-20-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-20-FeedForward-Drop (None, None, 1024)   0           Transformer-20-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-20-FeedForward-Add  (None, None, 1024)   0           Transformer-20-MultiHeadSelfAtten\n","                                                                 Transformer-20-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-20-FeedForward-Norm (None, None, 1024)   2048        Transformer-20-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-21-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-20-FeedForward-Norm[0\n","                                                                 Transformer-20-FeedForward-Norm[0\n","                                                                 Transformer-20-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-21-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-21-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-21-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-20-FeedForward-Norm[0\n","                                                                 Transformer-21-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-21-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-21-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-21-FeedForward (Fee (None, None, 1024)   8393728     Transformer-21-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-21-FeedForward-Drop (None, None, 1024)   0           Transformer-21-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-21-FeedForward-Add  (None, None, 1024)   0           Transformer-21-MultiHeadSelfAtten\n","                                                                 Transformer-21-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-21-FeedForward-Norm (None, None, 1024)   2048        Transformer-21-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-22-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-21-FeedForward-Norm[0\n","                                                                 Transformer-21-FeedForward-Norm[0\n","                                                                 Transformer-21-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-22-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-22-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-22-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-21-FeedForward-Norm[0\n","                                                                 Transformer-22-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-22-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-22-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-22-FeedForward (Fee (None, None, 1024)   8393728     Transformer-22-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-22-FeedForward-Drop (None, None, 1024)   0           Transformer-22-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-22-FeedForward-Add  (None, None, 1024)   0           Transformer-22-MultiHeadSelfAtten\n","                                                                 Transformer-22-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-22-FeedForward-Norm (None, None, 1024)   2048        Transformer-22-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","Transformer-23-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-22-FeedForward-Norm[0\n","                                                                 Transformer-22-FeedForward-Norm[0\n","                                                                 Transformer-22-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","Transformer-23-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-23-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-23-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-22-FeedForward-Norm[0\n","                                                                 Transformer-23-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-23-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-23-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-23-FeedForward (Fee (None, None, 1024)   8393728     Transformer-23-MultiHeadSelfAtten\n","__________________________________________________________________________________________________\n","Transformer-23-FeedForward-Drop (None, None, 1024)   0           Transformer-23-FeedForward[0][0] \n","__________________________________________________________________________________________________\n","Transformer-23-FeedForward-Add  (None, None, 1024)   0           Transformer-23-MultiHeadSelfAtten\n","                                                                 Transformer-23-FeedForward-Dropou\n","__________________________________________________________________________________________________\n","Transformer-23-FeedForward-Norm (None, None, 1024)   2048        Transformer-23-FeedForward-Add[0]\n","__________________________________________________________________________________________________\n","dense_145 (Dense)               (None, None, 2)      2050        Transformer-23-FeedForward-Norm[0\n","__________________________________________________________________________________________________\n","masked_softmax_1 (MaskedSoftmax (None, None, 2)      0           dense_145[0][0]                  \n","__________________________________________________________________________________________________\n","permute_1 (Permute)             (None, 2, None)      0           masked_softmax_1[0][0]           \n","==================================================================================================\n","Total params: 324,474,882\n","Trainable params: 324,474,882\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TTDznSI483Uo","colab_type":"text"},"source":["# 评估函数"]},{"cell_type":"code","metadata":{"trusted":true,"id":"aBwxu8Lw83Up","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855775055,"user_tz":-480,"elapsed":1083,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["def sparse_categorical_crossentropy(y_true, y_pred):\n","    # y_true需要重新明确一下shape和dtype\n","    y_true = K.reshape(y_true, K.shape(y_pred)[:-1])\n","    y_true = K.cast(y_true, 'int32')\n","    y_true = K.one_hot(y_true, K.shape(y_pred)[2])\n","    # 计算交叉熵\n","    return K.mean(K.categorical_crossentropy(y_true, y_pred))\n","\n","\n","def sparse_accuracy(y_true, y_pred):\n","    # y_true需要重新明确一下shape和dtype\n","    y_true = K.reshape(y_true, K.shape(y_pred)[:-1])\n","    y_true = K.cast(y_true, 'int32')\n","    # 计算准确率\n","    y_pred = K.cast(K.argmax(y_pred, axis=2), 'int32')\n","    return K.mean(K.cast(K.equal(y_true, y_pred), K.floatx()))"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cFxg5d8T83Uq","colab_type":"text"},"source":["# 编译模型"]},{"cell_type":"code","metadata":{"trusted":true,"id":"T-r4oWgd83Ur","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855789528,"user_tz":-480,"elapsed":1019,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["model.compile(\n","    loss=sparse_categorical_crossentropy,\n","    optimizer=Adam(learing_rate),\n","    metrics=[sparse_accuracy]\n",")"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FCbOxQOM83Uu","colab_type":"text"},"source":["# 答案抽取"]},{"cell_type":"code","metadata":{"trusted":true,"id":"kSj4Ri9p83Uu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855897853,"user_tz":-480,"elapsed":1016,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["def extract_answer(question, context, max_a_len=16):\n","    \"\"\"\n","    抽取答案函数\n","    \"\"\"\n","    max_q_len = 64\n","    q_token_ids = tokenizer.encode(question, maxlen=max_q_len)[0]\n","    c_token_ids = tokenizer.encode(\n","        context, maxlen=maxlen - len(q_token_ids) + 1\n","    )[0]\n","    token_ids = q_token_ids + c_token_ids[1:]\n","    segment_ids = [0] * len(q_token_ids) + [1] * (len(c_token_ids) - 1)\n","    c_tokens = tokenizer.tokenize(context)[1:-1]\n","    mapping = tokenizer.rematch(context, c_tokens)\n","    probas = model.predict([[token_ids], [segment_ids]])[0]\n","    probas = probas[:, len(q_token_ids):-1]\n","    start_end, score = None, -1\n","    for start, p_start in enumerate(probas[0]):\n","        for end, p_end in enumerate(probas[1]):\n","            if end >= start and end < start + max_a_len:\n","                if p_start * p_end > score:\n","                    start_end = (start, end)\n","                    score = p_start * p_end\n","    start, end = start_end\n","    return context[mapping[start][0]:mapping[end][-1] + 1]"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UPJHj4nS83Uw","colab_type":"text"},"source":["# 预测文件生成"]},{"cell_type":"code","metadata":{"trusted":true,"id":"1yBZNbHu83Uw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855904541,"user_tz":-480,"elapsed":1088,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["def predict_to_file(infile, out_file):\n","    \"\"\"预测结果到文件，方便提交\n","    \"\"\"\n","    fw = open(out_file, 'w', encoding='utf-8')\n","    R = {}\n","    for d in tqdm(load_data(infile)):\n","        a = extract_answer(d[2], d[1])\n","        R[d[0]] = a\n","    R = json.dumps(R, ensure_ascii=False, indent=4)\n","    fw.write(R)\n","    fw.close()"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c4ceYNdp83Uz","colab_type":"text"},"source":["# 官方评估函数"]},{"cell_type":"code","metadata":{"id":"DkKAIfoTe6hN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855908410,"user_tz":-480,"elapsed":1564,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["import sys\n","import io\n","import json\n","sys.path.append('/content/drive/My Drive/kaikeba/project03/roberta/data')\n","from evaluate import evaluate as src_evaluate\n","from collections import OrderedDict"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"wNrSRL0i83Uz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855912948,"user_tz":-480,"elapsed":1310,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["def evaluate(filename):\n","    \"\"\"\n","    评测函数（官方提供评测脚本evaluate.py）\n","    \"\"\"\n","    predict_to_file(filename, filename + '.pred.json')\n","    ref_ans = json.load(io.open(filename))\n","    pred_ans = json.load(io.open(filename + '.pred.json'))\n","    F1, EM, TOTAL, SKIP = src_evaluate(ref_ans, pred_ans)\n","    output_result = OrderedDict()\n","    output_result['F1'] = '%.3f' % F1\n","    output_result['EM'] = '%.3f' % EM\n","    output_result['TOTAL'] = TOTAL\n","    output_result['SKIP'] = SKIP\n","    return output_result\n","\n","\n","class Evaluator(keras.callbacks.Callback):\n","    \"\"\"\n","    评估和保存模型\n","    \"\"\"\n","    def __init__(self):\n","        self.best_val_f1 = 0.\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        metrics = evaluate(\n","            os.path.join(data_dir,'dev.json')\n","            # os.path.join(data_dir,'demo_dev.json')\n","        )\n","        if float(metrics['F1']) >= self.best_val_f1:\n","            self.best_val_f1 = float(metrics['F1'])\n","            model.save_weights(os.path.join(output_dir,'roberta_best_model.weights'))\n","            model.save(os.path.join(output_dir,'roberta_best_model.h5'))\n","        metrics['BEST_F1'] = self.best_val_f1\n","        print(metrics)"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rivf9wn883U1","colab_type":"text"},"source":["# 获取数据"]},{"cell_type":"code","metadata":{"trusted":true,"id":"z_cSRxhH83U2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595855923019,"user_tz":-480,"elapsed":1471,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}}},"source":["train_generator = data_generator(train_data, batch_size)\n","evaluator = Evaluator()"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kJi3sNmT83U4","colab_type":"text"},"source":["# 模型训练"]},{"cell_type":"code","metadata":{"scrolled":true,"trusted":true,"id":"VlHXytC583U4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":199},"outputId":"9c2f84d7-3280-4e77-f4e2-0be3a7d3b94a"},"source":["epochs=5\n","model.fit_generator(\n","    train_generator.forfit(),\n","    steps_per_epoch=len(train_generator),\n","    epochs=epochs,\n","    verbose=1,\n","    callbacks=[evaluator]\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/5\n","25/25 [==============================] - 49s 2s/step - loss: 3.4219 - sparse_accuracy: 0.2800\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1417/1417 [01:59<00:00, 11.89it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["OrderedDict([('F1', '44.755'), ('EM', '31.193'), ('TOTAL', 1417), ('SKIP', 0), ('BEST_F1', 44.755)])\n","Epoch 2/5\n","25/25 [==============================] - 24s 959ms/step - loss: 0.6342 - sparse_accuracy: 0.8700\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 1417/1417 [01:58<00:00, 11.94it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"RjVWAQBF83U6","colab_type":"text"},"source":["# 加载最优模型"]},{"cell_type":"code","metadata":{"id":"N9nOPUziNhBT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"status":"ok","timestamp":1595826685996,"user_tz":-480,"elapsed":428210,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}},"outputId":"980c3238-a34e-4de4-8b69-b38db9a776af"},"source":["from keras.models import load_model\n","model=load_model(os.path.join(output_dir,'roberta_best_model.h5'),custom_objects={'MaskedSoftmax':MaskedSoftmax,'sparse_accuracy':sparse_accuracy})\n","print(evaluate(os.path.join(data_dir,'dev.json')))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","100%|██████████| 1417/1417 [00:50<00:00, 27.86it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["OrderedDict([('F1', '41.801'), ('EM', '26.888'), ('TOTAL', 1417), ('SKIP', 0)])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3-R143V5FZll","colab_type":"code","colab":{}},"source":["# from keras.models import load_model\n","# model=load_model(os.path.join(output_dir,'roberta_best_model.h5'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"id":"m7dtNdk683U7","colab_type":"code","colab":{}},"source":["# model.load_weights(os.path.join(data_dir,'best_model.weights'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"srxSNpeD83U9","colab_type":"text"},"source":["# 预测结果"]},{"cell_type":"markdown","metadata":{"id":"qPD-1vOd83U-","colab_type":"text"},"source":["## Test1"]},{"cell_type":"code","metadata":{"trusted":false,"id":"qMVJ1nig83U-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595828394013,"user_tz":-480,"elapsed":2136160,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}},"outputId":"d9c15ece-197c-4456-a313-9aef4edb0c81"},"source":["predict_to_file(os.path.join(data_dir,'test1.json'), os.path.join(output_dir,'pred1.json'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 50000/50000 [28:26<00:00, 29.29it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"bZZDFVTl83VA","colab_type":"text"},"source":["## Test2"]},{"cell_type":"code","metadata":{"trusted":false,"id":"EnpQLIO-83VA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595830084711,"user_tz":-480,"elapsed":3826850,"user":{"displayName":"闫强","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtIy4F1fEx9VFx9tRiQTl05Gvm4ui2B5sE-g2J=s64","userId":"07650022386608013289"}},"outputId":"905852c2-6f07-4e67-8f60-5dc9cc83c79d"},"source":["predict_to_file(os.path.join(data_dir,'test2.json'),  os.path.join(output_dir,'pred2.json'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 50000/50000 [28:09<00:00, 29.59it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"GrUWFdMc83VC","colab_type":"text"},"source":["# 保存上传结果"]},{"cell_type":"code","metadata":{"trusted":false,"id":"52ciUW7B83VF","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"64JXuFwBDJ8Q","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mUcBeI1xbVJd","colab_type":"code","colab":{}},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbXCbIPhFYkr","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GMajUvq0Neiq","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"78eyIPI5Nfwv","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}