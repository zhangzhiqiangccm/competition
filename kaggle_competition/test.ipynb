{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '''from collections import defaultdict\n",
    "def dd():\n",
    "    return defaultdict(float)\n",
    "'''\n",
    "with open('utils.py','w') as f:\n",
    "    f.write(s)\n",
    "\n",
    "from utils import dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import lightgbm as lgb\n",
    "import riiideducation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from multiprocessing import cpu_count\n",
    "import pickle as pk\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def questions_and_lecture_parsing():\n",
    "    q = pd.read_csv('../input/riiid-test-answer-prediction/questions.csv').fillna('')\n",
    "    bundle_dict = q.groupby('bundle_id')['question_id'].count().to_dict()\n",
    "    q.loc[:, 'small_part'] = -1\n",
    "    cnt = 0\n",
    "    for part in range(1, 8):\n",
    "        end = q[q.part == part][q[q.part == part]['question_id'].diff(-1) != -1]['question_id'].values\n",
    "        start = q[q.part == part][q[q.part == part]['question_id'].diff() != 1]['question_id'].values\n",
    "        for s,t in zip(start, end):\n",
    "            q.loc[s:t, 'small_part'] = cnt\n",
    "            cnt += 1\n",
    "\n",
    "    q['part'] -= 1\n",
    "    \n",
    "    for i in range(3):\n",
    "        q[f'tags{i}'] = q['tags'].apply(lambda x: [int(item) for item in x.split()][i] if len(x.split()) > i else np.nan)\n",
    "    for i in range(1,3):\n",
    "        q[f'tags{i}'] = q[f'tags{i-1}']*200+q[f'tags{i}']\n",
    "        \n",
    "    q['tags_count'] = q['tags'].apply(lambda x: len(x.split()))  \n",
    "    return q\n",
    "\n",
    "def mdiv(a, b):\n",
    "    if b == 0:\n",
    "        return np.nan\n",
    "    return a*1./b\n",
    "\n",
    "def ll(predicted, actual, eps=1e-14):\n",
    "    predicted = np.clip(predicted, eps, 1-eps)\n",
    "    loss = -1*(actual * np.log(predicted) + (1 - actual) * np.log(1-predicted))\n",
    "    return loss\n",
    "\n",
    "# Random seed\n",
    "SEED = 42\n",
    "\n",
    "# Function to seed everything\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion for user stats with loops\n",
    "def add_features(df, \n",
    "        last_u_content_id_dict,\n",
    "        last_u_container_id_dict,\n",
    "        hist_u_answered_correctly_cnt_dict,\n",
    "        hist_u_elapsed_time_sum_dict,\n",
    "        hist_u_explanation_sum_dict,\n",
    "        hist_u_same_part_correctly_cnt_dict,\n",
    "        hist_u_same_content_id_correctly_cnt_dict,\n",
    "        timestamp_u,\n",
    "        hist_u_answered_correctly_sum_dict,\n",
    "        hist_u_score_sum_dict,\n",
    "        hist_u_same_part_correctly_sum_dict,\n",
    "        hist_u_same_content_id_correctly_sum_dict,\n",
    "        last_u_last_incorrect_timestamp_dict,\n",
    "        hist_u_last_incorrect_cnt_dict,\n",
    "        hist_u_lag_time_sum_dict,\n",
    "        global_avg_q_time_dict, prior_question_elapsed_time_mean, global_content_cnt_dict,\n",
    "        update = True):\n",
    "  \n",
    "    # -----------------------------------------------------------------------\n",
    "    last_u_diff_container_id = np.zeros(len(df), dtype = np.float32)\n",
    "    timestamp_u_recency_1 = np.zeros(len(df), dtype = np.float32) \n",
    "    timestamp_u_gap_time_ratio = np.zeros(len(df), dtype = np.float32) \n",
    "    timestamp_u_avg_time_ratio = np.zeros(len(df), dtype = np.float32) \n",
    "    timestamp_u_lag_time_ratio = np.zeros(len(df), dtype = np.float32) \n",
    "    timestamp_u_lag_time = np.zeros(len(df), dtype = np.float32)\n",
    "\n",
    "    hist_u_lag_time_raito = np.zeros(len(df), dtype = np.float32) \n",
    "    hist_u_answered_correctly_ratio = np.zeros(len(df), dtype = np.float32) \n",
    "    hist_u_elapsed_time_ratio = np.zeros(len(df), dtype = np.float32) \n",
    "    hist_u_explanation_ratio = np.zeros(len(df), dtype = np.float32)\n",
    "    hist_u_score_ratio = np.zeros(len(df), dtype = np.float32) \n",
    "    hist_u_same_part_sum = np.zeros(len(df), dtype = np.float32)\n",
    "    hist_u_same_part_cnt = np.zeros(len(df), dtype = np.float32)\n",
    "    hist_u_same_part_ratio = np.zeros(len(df), dtype = np.float32)\n",
    "    hist_u_same_content_id_sum = np.zeros(len(df), dtype = np.float32)\n",
    "    hist_u_same_content_id_cnt = np.zeros(len(df), dtype = np.float32)\n",
    "    hist_u_same_content_id_ratio = np.zeros(len(df), dtype = np.float32)\n",
    "    hist_u_last_incorrect_timestamp = np.zeros(len(df), dtype = np.float32)\n",
    "    hist_u_last_incorrect_cnt = np.zeros(len(df), dtype = np.float32)\n",
    "    # User Question\n",
    "    answered_correctly_uq_count = np.zeros(len(df), dtype = np.int32)\n",
    "    # -----------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    for num, row in tqdm(enumerate(df[['user_id','answered_correctly','content_id','prior_question_elapsed_time', \n",
    "                                  'prior_question_had_explanation', 'timestamp','contentid_mean','task_container_id','part']].values)):\n",
    "                \n",
    "        last_u_content_id = last_u_content_id_dict.get(row[0], np.nan)\n",
    "        last_u_container_id = last_u_container_id_dict.get(row[0], np.nan)\n",
    "        \n",
    "        last_u_diff_container_id[num] = row[7] - last_u_container_id   # 1\n",
    "\n",
    "        last_u_sum_time = row[3] * global_content_cnt_dict.get(last_u_content_id, 1)\n",
    "        sum_time_consum = global_avg_q_time_dict.get(row[2], prior_question_elapsed_time_mean) * global_content_cnt_dict.get(row[2], 1)\n",
    "        \n",
    "        # Client features assignation\n",
    "        # ------------------------------------------------------------------\n",
    "            \n",
    "        if len(timestamp_u[row[0]]) == 0:\n",
    "            timestamp_u_recency_1[num] = np.nan     # 2\n",
    "            timestamp_u_gap_time_ratio[num] = np.nan  # 3\n",
    "            timestamp_u_avg_time_ratio[num] = np.nan  # 4\n",
    "            timestamp_u_lag_time_ratio[num] = np.nan  # 5\n",
    "            timestamp_u_lag_time[num]  = np.nan # 6\n",
    "            \n",
    "        elif len(timestamp_u[row[0]]) == 1:\n",
    "            timestamp_u_recency_1[num] = row[5] - timestamp_u[row[0]][0]\n",
    "            timestamp_u_gap_time_ratio[num] = mdiv(sum_time_consum , (row[5] - timestamp_u[row[0]][0]))\n",
    "            timestamp_u_avg_time_ratio[num] = mdiv((row[5] - timestamp_u[row[0]][0]), global_content_cnt_dict.get(row[2], 1))\n",
    "            timestamp_u_lag_time_ratio[num] = np.nan\n",
    "            timestamp_u_lag_time[num]  = np.nan\n",
    "            \n",
    "        elif len(timestamp_u[row[0]]) == 2:\n",
    "            timestamp_u_recency_1[num] = row[5] - timestamp_u[row[0]][1]\n",
    "            timestamp_u_gap_time_ratio[num] = mdiv(sum_time_consum , (row[5] - timestamp_u[row[0]][1]))\n",
    "            timestamp_u_avg_time_ratio[num] = mdiv((row[5] - timestamp_u[row[0]][1]) , global_content_cnt_dict.get(row[2], 1))\n",
    "            timestamp_u_lag_time_ratio[num] = mdiv((timestamp_u[row[0]][1] - timestamp_u[row[0]][0] - last_u_sum_time) , (row[5] - timestamp_u[row[0]][1]+1))\n",
    "            timestamp_u_lag_time[num] = (timestamp_u[row[0]][1] - timestamp_u[row[0]][0] - last_u_sum_time)\n",
    "            \n",
    "        elif len(timestamp_u[row[0]]) == 3:\n",
    "            timestamp_u_recency_1[num] = row[5] - timestamp_u[row[0]][2]\n",
    "            timestamp_u_gap_time_ratio[num] = mdiv(sum_time_consum , (row[5] - timestamp_u[row[0]][2]))\n",
    "            timestamp_u_avg_time_ratio[num] = mdiv((row[5] - timestamp_u[row[0]][2]) , global_content_cnt_dict.get(row[2], 1))\n",
    "            timestamp_u_lag_time_ratio[num] = mdiv((timestamp_u[row[0]][2] - timestamp_u[row[0]][1] - sum_time_consum) , (row[5] - timestamp_u[row[0]][2]+1))\n",
    "            timestamp_u_lag_time[num] = (timestamp_u[row[0]][2] - timestamp_u[row[0]][1] - last_u_sum_time)\n",
    "\n",
    "        if timestamp_u_lag_time[num] is not np.nan:    \n",
    "            hist_u_lag_time_sum_dict[row[0]] += max(0, min(timestamp_u_lag_time[num], 300*1000))\n",
    "        hist_u_lag_time_raito[num] = mdiv(hist_u_lag_time_sum_dict[row[0]], hist_u_answered_correctly_cnt_dict[row[0]])\n",
    "\n",
    "                \n",
    "        hist_u_answered_correctly_ratio[num] = mdiv(hist_u_answered_correctly_sum_dict[row[0]], hist_u_answered_correctly_cnt_dict[row[0]])\n",
    "        hist_u_elapsed_time_ratio[num] = mdiv(hist_u_elapsed_time_sum_dict[row[0]], hist_u_answered_correctly_cnt_dict[row[0]])\n",
    "        hist_u_explanation_ratio[num] = mdiv(hist_u_explanation_sum_dict[row[0]], hist_u_answered_correctly_cnt_dict[row[0]])\n",
    "            \n",
    "        hist_u_score_ratio[num] = mdiv(hist_u_score_sum_dict[row[0]], hist_u_answered_correctly_cnt_dict[row[0]])\n",
    "        \n",
    "        hist_u_same_part_sum[num] = hist_u_same_part_correctly_sum_dict[row[0]][row[8]]\n",
    "        hist_u_same_part_cnt[num] = hist_u_same_part_correctly_cnt_dict[row[0]][row[8]]\n",
    "        hist_u_same_part_ratio[num] = mdiv(hist_u_same_part_sum[num], hist_u_same_part_cnt[num])\n",
    "\n",
    "        hist_u_same_content_id_sum[num] = hist_u_same_content_id_correctly_sum_dict[row[0]][row[2]]\n",
    "        hist_u_same_content_id_cnt[num] = hist_u_same_content_id_correctly_cnt_dict[row[0]][row[2]]        \n",
    "        hist_u_same_content_id_ratio[num] = mdiv(hist_u_same_content_id_sum[num], hist_u_same_content_id_cnt[num])\n",
    "    \n",
    "        hist_u_last_incorrect_timestamp[num] = row[5] - last_u_last_incorrect_timestamp_dict[row[0]]\n",
    "        hist_u_last_incorrect_cnt[num] = hist_u_last_incorrect_cnt_dict[row[0]]\n",
    "        \n",
    "        \n",
    "        # ------------------------------------------------------------------\n",
    "        # Client features updates\n",
    "        hist_u_answered_correctly_cnt_dict[row[0]] += 1\n",
    "        hist_u_elapsed_time_sum_dict[row[0]] += row[3]\n",
    "        hist_u_explanation_sum_dict[row[0]] += int(row[4])\n",
    "        hist_u_same_part_correctly_cnt_dict[row[0]][row[8]] +=1\n",
    "        hist_u_same_content_id_correctly_cnt_dict[row[0]][row[2]] += 1\n",
    "\n",
    "        if len(timestamp_u[row[0]])==0 or row[5]!=timestamp_u[row[0]][-1]:\n",
    "            last_u_content_id_dict[row[0]] = row[2]\n",
    "            if len(timestamp_u[row[0]]) == 3:\n",
    "                timestamp_u[row[0]].pop(0)\n",
    "                timestamp_u[row[0]].append(row[5])\n",
    "            else:\n",
    "                timestamp_u[row[0]].append(row[5])\n",
    "        if len(timestamp_u[row[0]])!=0 or row[5]==timestamp_u[row[0]][-1]:\n",
    "            last_u_container_id_dict[row[0]] = row[7]\n",
    "        \n",
    "        # Flag for training and inference\n",
    "        if update:\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client features updates\n",
    "            hist_u_answered_correctly_sum_dict[row[0]] += row[1]\n",
    "            hist_u_score_sum_dict[row[0]] += (1 if row[1] == 1 else -1) * ll(row[6], row[1])\n",
    "            hist_u_same_part_correctly_sum_dict[row[0]][row[8]] += row[1]\n",
    "            hist_u_same_content_id_correctly_sum_dict[row[0]][row[2]] += row[1]\n",
    "            if row[1] == 0:\n",
    "                last_u_last_incorrect_timestamp_dict[row[0]] = row[5]\n",
    "                hist_u_last_incorrect_cnt_dict[row[0]] = 0\n",
    "            else:\n",
    "                hist_u_last_incorrect_cnt_dict[row[0]] += 1\n",
    "\n",
    "    user_df = pd.DataFrame({\n",
    "                            'last_u_diff_container_id': last_u_diff_container_id, \n",
    "                            'timestamp_u_recency_1': timestamp_u_recency_1, \n",
    "                            'timestamp_u_gap_time_ratio': timestamp_u_gap_time_ratio, \n",
    "                            'timestamp_u_avg_time_ratio': timestamp_u_avg_time_ratio, \n",
    "                            'timestamp_u_lag_time_ratio': timestamp_u_lag_time_ratio, \n",
    "                            'timestamp_u_lag_time': timestamp_u_lag_time, \n",
    "        \n",
    "                            'hist_u_lag_time_raito': hist_u_lag_time_raito,\n",
    "                            'hist_u_answered_correctly_ratio': hist_u_answered_correctly_ratio, \n",
    "                            'hist_u_elapsed_time_ratio': hist_u_elapsed_time_ratio, \n",
    "                            'hist_u_explanation_ratio': hist_u_explanation_ratio,\n",
    "                            'hist_u_score_ratio': hist_u_score_ratio, \n",
    "                            'hist_u_same_part_sum': hist_u_same_part_sum,\n",
    "                            'hist_u_same_part_cnt': hist_u_same_part_cnt,\n",
    "                            'hist_u_same_part_ratio': hist_u_same_part_ratio,\n",
    "                            'hist_u_same_content_id_sum': hist_u_same_content_id_sum,\n",
    "                            'hist_u_same_content_id_cnt':hist_u_same_content_id_cnt,\n",
    "                            'hist_u_same_content_id_ratio':hist_u_same_content_id_ratio,\n",
    "                            'hist_u_last_incorrect_timestamp':hist_u_last_incorrect_timestamp,\n",
    "                            'hist_u_last_incorrect_cnt':hist_u_last_incorrect_cnt,\n",
    "        \n",
    "                           })\n",
    "    \n",
    "    df = pd.concat([df.reset_index(drop=True), user_df], axis = 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def update_features(df, \n",
    "                    hist_u_answered_correctly_sum_dict, \n",
    "                    hist_u_score_sum_dict, \n",
    "                    hist_u_same_part_correctly_sum_dict, \n",
    "                    hist_u_same_content_id_correctly_sum_dict,\n",
    "                    last_u_last_incorrect_timestamp_dict,\n",
    "                    hist_u_last_incorrect_cnt_dict):\n",
    "    for row in df[['user_id','answered_correctly','content_id','prior_question_elapsed_time', \n",
    "                    'prior_question_had_explanation', 'timestamp','contentid_mean',\n",
    "                   'task_container_id','part','content_type_id']].values:\n",
    "        if row[-1] == 0:\n",
    "            # ------------------------------------------------------------------\n",
    "            # Client features updates\n",
    "            hist_u_answered_correctly_sum_dict[row[0]] += row[1]\n",
    "            hist_u_score_sum_dict[row[0]] += (1 if row[1] == 1 else -1) * ll(row[6], row[1])\n",
    "            hist_u_same_part_correctly_sum_dict[row[0]][row[8]] += row[1]\n",
    "            hist_u_same_content_id_correctly_sum_dict[row[0]][row[2]] += row[1]\n",
    "            if row[1] == 0:\n",
    "                last_u_last_incorrect_timestamp_dict[row[0]] = row[5]\n",
    "                hist_u_last_incorrect_cnt_dict[row[0]] = 0\n",
    "            else:\n",
    "                hist_u_last_incorrect_cnt_dict[row[0]] += 1\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(TARGET, FEATURES, model, questions_df, prior_question_elapsed_time_mean, features_dicts, global_dicts):\n",
    "    \n",
    "    # Get feature dict\n",
    "    last_u_content_id_dict = features_dicts['last_u_content_id_dict']\n",
    "    last_u_container_id_dict = features_dicts['last_u_container_id_dict']\n",
    "    hist_u_answered_correctly_cnt_dict = features_dicts['hist_u_answered_correctly_cnt_dict']\n",
    "    hist_u_elapsed_time_sum_dict = features_dicts['hist_u_elapsed_time_sum_dict']\n",
    "    hist_u_explanation_sum_dict = features_dicts['hist_u_explanation_sum_dict']\n",
    "    hist_u_same_part_correctly_cnt_dict = features_dicts['hist_u_same_part_correctly_cnt_dict']\n",
    "    hist_u_same_content_id_correctly_cnt_dict = features_dicts['hist_u_same_content_id_correctly_cnt_dict']\n",
    "    timestamp_u = features_dicts['timestamp_u']\n",
    "    hist_u_answered_correctly_sum_dict = features_dicts['hist_u_answered_correctly_sum_dict']\n",
    "    hist_u_score_sum_dict = features_dicts['hist_u_score_sum_dict']\n",
    "    hist_u_same_part_correctly_sum_dict = features_dicts['hist_u_same_part_correctly_sum_dict']\n",
    "    hist_u_same_content_id_correctly_sum_dict = features_dicts['hist_u_same_content_id_correctly_sum_dict']\n",
    "    last_u_last_incorrect_timestamp_dict = features_dicts['last_u_last_incorrect_timestamp_dict']\n",
    "    hist_u_last_incorrect_cnt_dict = features_dicts['hist_u_last_incorrect_cnt_dict']\n",
    "    hist_u_lag_time_sum_dict = features_dicts['hist_u_lag_time_sum_dict']\n",
    "    \n",
    "    # Get global dict\n",
    "    global_avg_q_time_dict = global_dicts['global_avg_q_time_dict']\n",
    "    prior_question_elapsed_time_mean = global_dicts['prior_question_elapsed_time_mean']\n",
    "    global_content_cnt_dict = global_dicts['global_content_cnt_dict']\n",
    "    contentidmean_dict = global_dicts['contentidmean_dict']\n",
    "    \n",
    "    # Get api iterator and predictor\n",
    "    env = riiideducation.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    set_predict = env.predict\n",
    "    \n",
    "    previous_test_df = None\n",
    "    for (test_df, sample_prediction_df) in iter_test:\n",
    "        if previous_test_df is not None:\n",
    "            previous_test_df[TARGET] = eval(test_df[\"prior_group_answers_correct\"].iloc[0])\n",
    "            previous_test_df = pd.merge(previous_test_df, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "            previous_test_df['contentid_mean'] = previous_test_df['content_id'].map(lambda x:contentidmean_dict.get(x,np.nan))\n",
    "            update_features(previous_test_df,\n",
    "                    hist_u_answered_correctly_sum_dict, \n",
    "                    hist_u_score_sum_dict, \n",
    "                    hist_u_same_part_correctly_sum_dict, \n",
    "                    hist_u_same_content_id_correctly_sum_dict,\n",
    "                    last_u_last_incorrect_timestamp_dict,\n",
    "                    hist_u_last_incorrect_cnt_dict)\n",
    "                            \n",
    "        previous_test_df = test_df.copy()\n",
    "        test_df = test_df[test_df['content_type_id'] == 0].reset_index(drop = True)\n",
    "        test_df['prior_question_had_explanation'] = test_df.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "        test_df['prior_question_elapsed_time'].fillna(prior_question_elapsed_time_mean, inplace = True)\n",
    "        test_df = pd.merge(test_df, questions_df, left_on = 'content_id', right_on = 'question_id', how = 'left')\n",
    "        test_df[TARGET] = 0\n",
    "        test_df['contentid_mean'] = test_df['content_id'].map(lambda x:contentidmean_dict.get(x,np.nan))\n",
    "        test_df = add_features(test_df,\n",
    "        last_u_content_id_dict,\n",
    "        last_u_container_id_dict,\n",
    "        hist_u_answered_correctly_cnt_dict,\n",
    "        hist_u_elapsed_time_sum_dict,\n",
    "        hist_u_explanation_sum_dict,\n",
    "        hist_u_same_part_correctly_cnt_dict,\n",
    "        hist_u_same_content_id_correctly_cnt_dict,\n",
    "        timestamp_u,\n",
    "        hist_u_answered_correctly_sum_dict,\n",
    "        hist_u_score_sum_dict,\n",
    "        hist_u_same_part_correctly_sum_dict,\n",
    "        hist_u_same_content_id_correctly_sum_dict,\n",
    "        last_u_last_incorrect_timestamp_dict,\n",
    "        hist_u_last_incorrect_cnt_dict,\n",
    "        hist_u_lag_time_sum_dict,\n",
    "        global_avg_q_time_dict, prior_question_elapsed_time_mean, global_content_cnt_dict,\n",
    "        update = False)\n",
    "        test_df[TARGET] =  model.predict(test_df[FEATURES])\n",
    "        set_predict(test_df[['row_id', TARGET]])\n",
    "        \n",
    "    print('Job Done')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "META_PATHS = '../input/meta-files/meta.test.pkl'\n",
    "TARGET, FEATURES, model, questions_df, prior_question_elapsed_time_mean, features_dicts, global_dicts = pd.read_pickle(META_PATHS)\n",
    "inference(TARGET, FEATURES, model, questions_df, prior_question_elapsed_time_mean, features_dicts, global_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
